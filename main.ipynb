{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a1ff8-aa31-4171-85a1-0bb500d276a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, NamedTuple\n",
    "\n",
    "import os\n",
    "from src.core._mlflow import mlflow_init\n",
    "from dotenv import load_dotenv\n",
    "from mlflow.entities import Experiment\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.core.switcher import ModelSwitcher\n",
    "from src.custom.dataprep import CustomDataPrep, CustomDataSplitter\n",
    "from src.custom.trainer import CustomModelTrainer\n",
    "from src.custom.tuner import CustomModelTuner\n",
    "from src.models.params import Estimators, Params\n",
    "from src.services.data_fetch import DataFetch\n",
    "from src.services.pipeline import MLPipeline\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi  # noqa: E402\n",
    "\n",
    "\n",
    "class DataPrepParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Named tuple to hold the parameters for data preparation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    selected_features : List[str], optional\n",
    "        A list of feature names to be selected for training. Default is None.\n",
    "    is_drop_id : bool\n",
    "        Whether to drop the ID column from the dataset. Default is True.\n",
    "    feature_Id : List[str], optional\n",
    "        A list of ID column names to be dropped. Default is None.\n",
    "    \"\"\"\n",
    "\n",
    "    selected_features: List[str] = None\n",
    "    is_drop_id: bool = True\n",
    "    feature_Id: List[str] = None\n",
    "\n",
    "\n",
    "class DataSplitterParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Named tuple to hold the parameters for splitting the dataset.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    test_size : float\n",
    "        Proportion of the dataset to include in the test split. Default is 0.2.\n",
    "    is_stratified : bool\n",
    "        Whether to perform stratified splitting of the dataset. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    test_size: float = 0.2\n",
    "    is_stratified: bool = True\n",
    "\n",
    "\n",
    "class TrainParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Named tuple to hold the parameters for the model training.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    pre_processing : Params\n",
    "        Parameters for the preprocessing step in the pipeline. Default is a PowerTransformer\n",
    "        with the 'yeo-johnson' method and standardization enabled.\n",
    "    estimator : ClfSwitcher\n",
    "        The machine learning model or estimator to be used in the pipeline. Default is an\n",
    "        XGBClassifier with 100 estimators, 'binary:logistic' objective, and random state set to 42.\n",
    "    \"\"\"\n",
    "\n",
    "    pre_processing: Params = Params(\n",
    "        method=PowerTransformer(\n",
    "            method=\"yeo-johnson\",\n",
    "            standardize=True,\n",
    "        )\n",
    "    )\n",
    "    estimators: Estimators = Estimators(\n",
    "        xgboost=XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            objective=\"binary:logistic\",\n",
    "            random_state=42,\n",
    "        ),\n",
    "        logistic_regression=LogisticRegression(max_iter=1000),\n",
    "    )\n",
    "    n_splits: int = 5\n",
    "    random_state: int = 42\n",
    "\n",
    "\n",
    "class TunerParams(NamedTuple):\n",
    "    \"\"\"\n",
    "    Named tuple to hold the parameters for model tuning.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    pipeline : Pipeline\n",
    "        A scikit-learn Pipeline object containing preprocessing and model steps.\n",
    "        Default is a pipeline with a PowerTransformer and a ModelSwitcher.\n",
    "    param_grid : List[Params]\n",
    "        A list of parameter grids to be used for hyperparameter tuning.\n",
    "        Default includes parameter grids for XGBClassifier and LogisticRegression.\n",
    "    scoring : str\n",
    "        The scoring metric to be used for evaluating the models during tuning. Default is \"f1_micro\".\n",
    "    enable_mlflow : bool\n",
    "        Whether to enable MLflow logging during the tuning process. Default is False.\n",
    "    cv : int\n",
    "        Number of cross-validation folds. Default is 5.\n",
    "    n_jobs : int\n",
    "        Number of jobs to run in parallel. Default is -1 (use all processors).\n",
    "    verbose : int\n",
    "        Verbosity level for logging. Default is 0.\n",
    "    \"\"\"\n",
    "\n",
    "    pipeline: Pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\n",
    "                \"pre_processing\",\n",
    "                PowerTransformer(method=\"yeo-johnson\", standardize=True),\n",
    "            ),\n",
    "            (\"model\", ModelSwitcher()),\n",
    "        ]\n",
    "    )\n",
    "    param_grid: List[Params] = [\n",
    "        Params(\n",
    "            model__estimator=[\n",
    "                XGBClassifier(\n",
    "                    n_estimators=100, objective=\"binary:logistic\", random_state=42\n",
    "                )\n",
    "            ],\n",
    "            model__estimator__max_depth=[3, 5, 7],\n",
    "            model__estimator__min_child_weight=[1, 3, 5],\n",
    "            model__estimator__subsample=[0.6, 0.8, 1.0],\n",
    "        ),\n",
    "        Params(\n",
    "            model__estimator=[LogisticRegression(max_iter=1000)],\n",
    "            model__estimator__C=[0.001, 0.01, 0.1],\n",
    "        ),\n",
    "    ]\n",
    "    scoring: str = \"f1_micro\"\n",
    "    enable_mlflow: bool = True\n",
    "    cv: int = 5\n",
    "    n_jobs: int = -1\n",
    "    verbose: int = 0\n",
    "\n",
    "\n",
    "def run(\n",
    "    data_prep_params: DataPrepParams,\n",
    "    data_splitter_params: DataSplitterParams,\n",
    "    train_params: TrainParams,\n",
    "    tuner_params: TunerParams,\n",
    "    experiment: Experiment = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run the entire pipeline.\n",
    "    \"\"\"\n",
    "    kaggle_api_client = KaggleApi()\n",
    "    _ = kaggle_api_client.authenticate()\n",
    "\n",
    "    data_fetch = DataFetch(kaggle_client=kaggle_api_client)\n",
    "    dataset = data_fetch.fetch()\n",
    "\n",
    "    data_prep = CustomDataPrep(\n",
    "        dataset=dataset,\n",
    "        selected_features=data_prep_params.selected_features,\n",
    "        is_drop_id=data_prep_params.is_drop_id,\n",
    "        feature_Id=data_prep_params.feature_Id,\n",
    "    )\n",
    "    data_splitter = CustomDataSplitter(\n",
    "        experiment=experiment,\n",
    "        test_size=data_splitter_params.test_size,\n",
    "        is_stratified=data_splitter_params.is_stratified,\n",
    "    )\n",
    "    model_trainer = CustomModelTrainer(\n",
    "        experiment=experiment,\n",
    "        pre_processing=train_params.pre_processing,\n",
    "        estimators=train_params.estimators,\n",
    "        n_splits=train_params.n_splits,\n",
    "        random_state=train_params.random_state,\n",
    "    )\n",
    "    model_tuner = CustomModelTuner(\n",
    "        tuner_params=tuner_params,\n",
    "        experiment=experiment,\n",
    "    )\n",
    "    ml = MLPipeline(\n",
    "        experiment=experiment,\n",
    "        data_prep=data_prep,\n",
    "        data_splitter=data_splitter,\n",
    "        model_trainer=model_trainer,\n",
    "        model_tuner=model_tuner,\n",
    "    )\n",
    "    ml.run_pipeline()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    experiment = mlflow_init(\n",
    "        experiment_name=\"Default\",\n",
    "        uri=os.getenv(\"MLFLOW_TRACKING_URI\"),\n",
    "    )\n",
    "\n",
    "    run(\n",
    "        data_prep_params=DataPrepParams(),\n",
    "        data_splitter_params=DataSplitterParams(),\n",
    "        train_params=TrainParams(),\n",
    "        tuner_params=TunerParams(),\n",
    "        experiment=experiment\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1129d-b0a3-45aa-b337-b18a937ea285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
